{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "852bcdaa",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mos\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtf\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_curve, auc, precision_score, recall_score, f1_score, accuracy_score\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from itertools import cycle\n",
    "import requests\n",
    "import zipfile\n",
    "from io import BytesIO\n",
    "\n",
    "\n",
    "# --- Configuration ---\n",
    "IMG_SIZE = (64, 64)\n",
    "BATCH_SIZE = 64\n",
    "NUM_CLASSES = 10\n",
    "EPOCHS = 25\n",
    "\n",
    "# Load dataframes\n",
    "try:\n",
    "    train_df = pd.read_csv('train.csv')\n",
    "    val_df = pd.read_csv('validation.csv')\n",
    "    test_df = pd.read_csv('test.csv')\n",
    "    class_names = list(pd.read_json('label_map.json', typ='series').index)\n",
    "\n",
    "    train_df['Filename'] = DATA_DIR + '/' + train_df['Filename']\n",
    "    val_df['Filename'] = DATA_DIR + '/' + val_df['Filename']\n",
    "    test_df['Filename'] = DATA_DIR + '/' + test_df['Filename']\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: train.csv, validation.csv, test.csv or label_map.json not found.\")\n",
    "    exit()\n",
    "\n",
    "\n",
    "def create_dataset(df, shuffle=False):\n",
    "    \"\"\"Creates a tf.data.Dataset from a pandas DataFrame.\"\"\"\n",
    "    image_paths = df['Filename'].values\n",
    "    labels = df['Label'].values\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((image_paths, labels))\n",
    "\n",
    "    def _parse_function(filename, label):\n",
    "        image_string = tf.io.read_file(filename)\n",
    "        image_decoded = tf.image.decode_jpeg(image_string, channels=3)\n",
    "        image = tf.image.convert_image_dtype(image_decoded, tf.float32)\n",
    "        image = tf.image.resize(image, IMG_SIZE)\n",
    "        return image, label\n",
    "\n",
    "    dataset = dataset.map(_parse_function, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    if shuffle:\n",
    "        dataset = dataset.shuffle(buffer_size=len(df))\n",
    "    dataset = dataset.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "    return dataset\n",
    "\n",
    "# Create datasets\n",
    "train_ds = create_dataset(train_df, shuffle=True)\n",
    "val_ds = create_dataset(val_df)\n",
    "test_ds = create_dataset(test_df)\n",
    "\n",
    "# --- 2. HYBRID MODEL DEFINITION (MODIFIED FOR FLEXIBILITY) ---\n",
    "def build_feature_model(input_shape, model_type='combined', num_classes=10):\n",
    "    \"\"\"Builds a model based on the specified feature type: global, local, or combined.\"\"\"\n",
    "    base_model = tf.keras.applications.VGG16(\n",
    "        include_top=False, weights='imagenet', input_shape=input_shape\n",
    "    )\n",
    "    base_model.trainable = False\n",
    "\n",
    "    inputs = tf.keras.Input(shape=input_shape)\n",
    "    x = tf.keras.applications.vgg16.preprocess_input(inputs)\n",
    "    \n",
    "    # Get outputs from VGG16 base\n",
    "    vgg16_output = base_model(x, training=False)\n",
    "    local_feature_layer_output = base_model.get_layer(\"block4_pool\").output\n",
    "    \n",
    "    # Create models for extracting specific features\n",
    "    base_model_functional = tf.keras.Model(inputs=base_model.input, outputs=vgg16_output)\n",
    "    local_model = tf.keras.Model(inputs=base_model.input, outputs=local_feature_layer_output)\n",
    "    \n",
    "    # Get feature maps\n",
    "    vgg16_feature_map = base_model_functional(x)\n",
    "    local_feature_map = local_model(x)\n",
    "\n",
    "    # --- Feature Streams ---\n",
    "    global_features = tf.keras.layers.GlobalAveragePooling2D(name=\"global_pool\")(vgg16_feature_map)\n",
    "    local_features = tf.keras.layers.Flatten(name=\"local_flatten\")(local_feature_map)\n",
    "\n",
    "    # --- Feature Selection/Fusion ---\n",
    "    if model_type == 'global':\n",
    "        final_features = global_features\n",
    "    elif model_type == 'local':\n",
    "        final_features = local_features\n",
    "    elif model_type == 'combined':\n",
    "        final_features = tf.keras.layers.Concatenate(name=\"fusion\")([global_features, local_features])\n",
    "    else:\n",
    "        raise ValueError(\"model_type must be one of 'global', 'local', or 'combined'\")\n",
    "\n",
    "    # --- Classification Head ---\n",
    "    classifier = tf.keras.layers.Dense(256, activation='relu', name=\"classifier_dense_1\")(final_features)\n",
    "    classifier = tf.keras.layers.Dropout(0.5, name=\"classifier_dropout\")(classifier)\n",
    "    outputs = tf.keras.layers.Dense(num_classes, activation='softmax', name=\"classifier_output\")(classifier)\n",
    "    \n",
    "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n",
    "\n",
    "# --- 3. MODEL TRAINING & EVALUATION LOOP ---\n",
    "model_types = ['global', 'local', 'combined']\n",
    "histories = {}\n",
    "evaluation_results = {}\n",
    "\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True),\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=1e-6)\n",
    "]\n",
    "\n",
    "# Get true labels once for all evaluations\n",
    "y_true = np.concatenate([y for x, y in test_ds], axis=0)\n",
    "\n",
    "for m_type in model_types:\n",
    "    print(f\"\\n{'='*20} TRAINING {m_type.upper()} MODEL {'='*20}\")\n",
    "    \n",
    "    # Build and compile the model\n",
    "    model = build_feature_model(IMG_SIZE + (3,), model_type=m_type, num_classes=NUM_CLASSES)\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    print(f\"--- Starting training for {m_type} model ---\")\n",
    "    history = model.fit(\n",
    "        train_ds, epochs=EPOCHS, validation_data=val_ds, callbacks=callbacks, verbose=1\n",
    "    )\n",
    "    histories[m_type] = history\n",
    "    \n",
    "    print(f\"\\n--- Evaluating {m_type} model ---\")\n",
    "    y_pred_probs = model.predict(test_ds)\n",
    "    y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "    \n",
    "    # Store results\n",
    "    evaluation_results[m_type] = {\n",
    "        'y_pred': y_pred,\n",
    "        'y_pred_probs': y_pred_probs,\n",
    "        'history': history\n",
    "    }\n",
    "\n",
    "# --- 4. VISUALIZATION & COMPARISON ---\n",
    "\n",
    "# --- Plot 1: Performance Metrics Comparison (NEW) ---\n",
    "def plot_model_comparison(results, y_true):\n",
    "    \"\"\"Plots a bar chart comparing performance metrics across models.\"\"\"\n",
    "    metrics_data = []\n",
    "    for model_name, result in results.items():\n",
    "        y_pred = result['y_pred']\n",
    "        accuracy = accuracy_score(y_true, y_pred)\n",
    "        precision = precision_score(y_true, y_pred, average='macro')\n",
    "        recall = recall_score(y_true, y_pred, average='macro')\n",
    "        f1 = f1_score(y_true, y_pred, average='macro')\n",
    "        \n",
    "        metrics_data.append({'Model': model_name.title(), 'Metric': 'Accuracy', 'Score': accuracy})\n",
    "        metrics_data.append({'Model': model_name.title(), 'Metric': 'Precision', 'Score': precision})\n",
    "        metrics_data.append({'Model': model_name.title(), 'Metric': 'Recall', 'Score': recall})\n",
    "        metrics_data.append({'Model': model_name.title(), 'Metric': 'F1-Score', 'Score': f1})\n",
    "        \n",
    "    df = pd.DataFrame(metrics_data)\n",
    "    \n",
    "    plt.figure(figsize=(12, 7))\n",
    "    sns.barplot(data=df, x='Metric', y='Score', hue='Model', palette='viridis')\n",
    "    plt.title('Model Performance Comparison', fontsize=18)\n",
    "    plt.ylabel('Score', fontsize=12)\n",
    "    plt.xlabel('Metric', fontsize=12)\n",
    "    plt.ylim(0, 1.05)\n",
    "    plt.legend(title='Model Type', fontsize=11)\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    plt.show()\n",
    "\n",
    "print(\"\\n--- Plotting Model Performance Comparison ---\")\n",
    "plot_model_comparison(evaluation_results, y_true)\n",
    "\n",
    "# --- Detailed Analysis of the BEST model (Combined) ---\n",
    "print(\"\\n--- Detailed Analysis of the Combined Model ---\")\n",
    "combined_results = evaluation_results['combined']\n",
    "y_pred = combined_results['y_pred']\n",
    "y_pred_probs = combined_results['y_pred_probs']\n",
    "history = combined_results['history']\n",
    "\n",
    "# --- Plot 2: Training History of Combined Model ---\n",
    "def plot_history(history):\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    ax1.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "    ax1.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "    ax1.set_title('Model Accuracy'); ax1.set_xlabel('Epoch'); ax1.set_ylabel('Accuracy')\n",
    "    ax1.legend(loc='lower right'); ax1.grid(True)\n",
    "    ax2.plot(history.history['loss'], label='Train Loss')\n",
    "    ax2.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    ax2.set_title('Model Loss'); ax2.set_xlabel('Epoch'); ax2.set_ylabel('Loss')\n",
    "    ax2.legend(loc='upper right'); ax2.grid(True)\n",
    "    plt.suptitle('Combined Model Training History', fontsize=16); plt.tight_layout(rect=[0, 0.03, 1, 0.95]); plt.show()\n",
    "\n",
    "print(\"\\n--- Plotting Training History for Combined Model ---\")\n",
    "plot_history(history)\n",
    "\n",
    "# --- Plot 3: Confusion Matrix ---\n",
    "def plot_confusion_matrix(y_true, y_pred, class_names):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.title('Confusion Matrix (Combined Model)', fontsize=16); plt.xlabel('Predicted Label'); plt.ylabel('True Label')\n",
    "    plt.show()\n",
    "\n",
    "print(\"\\n--- Plotting Confusion Matrix for Combined Model ---\")\n",
    "plot_confusion_matrix(y_true, y_pred, class_names)\n",
    "print(\"\\n--- Classification Report (Combined Model) ---\")\n",
    "print(classification_report(y_true, y_pred, target_names=class_names))\n",
    "\n",
    "# --- Plot 4: Multi-Class ROC AUC Curve ---\n",
    "def plot_roc_auc_curves(y_true, y_pred_probs, class_names):\n",
    "    y_true_bin = label_binarize(y_true, classes=range(len(class_names)))\n",
    "    fpr, tpr, roc_auc = dict(), dict(), dict()\n",
    "    for i in range(len(class_names)):\n",
    "        fpr[i], tpr[i], _ = roc_curve(y_true_bin[:, i], y_pred_probs[:, i])\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    colors = cycle(['aqua', 'darkorange', 'cornflowerblue', 'green', 'red', 'purple', 'brown', 'pink', 'gray', 'olive'])\n",
    "    for i, color in zip(range(len(class_names)), colors):\n",
    "        plt.plot(fpr[i], tpr[i], color=color, lw=2,\n",
    "                 label=f'ROC curve of class {class_names[i]} (area = {roc_auc[i]:0.2f})')\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "    plt.xlim([0.0, 1.0]); plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate'); plt.ylabel('True Positive Rate')\n",
    "    plt.title('Multi-Class ROC Curves (Combined Model)', fontsize=16)\n",
    "    plt.legend(loc=\"lower right\"); plt.grid(True); plt.show()\n",
    "\n",
    "print(\"\\n--- Plotting ROC AUC Curves for Combined Model ---\")\n",
    "plot_roc_auc_curves(y_true, y_pred_probs, class_names)\n",
    "\n",
    "# --- Plot 5: Sample Predictions ---\n",
    "def show_sample_predictions(dataset, model, class_names, num_samples=9):\n",
    "    plt.figure(figsize=(12, 12))\n",
    "    for images, labels in dataset.take(1):\n",
    "        # We need to use the combined model for these predictions\n",
    "        combined_model = build_feature_model(IMG_SIZE + (3,), model_type='combined', num_classes=NUM_CLASSES)\n",
    "        combined_model.set_weights(model.get_weights()) # Quick way to load weights, assumes last trained model is combined\n",
    "        \n",
    "        predictions = combined_model.predict(images)\n",
    "        predicted_labels = np.argmax(predictions, axis=1)\n",
    "        for i in range(num_samples):\n",
    "            ax = plt.subplot(3, 3, i + 1)\n",
    "            plt.imshow(images[i].numpy())\n",
    "            true_label = class_names[labels[i]]\n",
    "            predicted_label = class_names[predicted_labels[i]]\n",
    "            title_color = 'green' if true_label == predicted_label else 'red'\n",
    "            plt.title(f\"True: {true_label}\\nPred: {predicted_label}\", color=title_color)\n",
    "            plt.axis(\"off\")\n",
    "    plt.tight_layout(); plt.show()\n",
    "\n",
    "print(\"\\n--- Displaying Sample Predictions from the Test Set (using Combined Model) ---\")\n",
    "# The last trained model is the combined one, so we can use it directly\n",
    "show_sample_predictions(test_ds, model, class_names)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c74273",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
